{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load market data\n",
    "file_market = '../DataSet/market_train_df.csv'\n",
    "data_market = pd.read_csv(file_market, parse_dates =[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Create new column of data with \n",
    "market_date = np.empty(len(data_market.time))\n",
    "market_date = pd.Series(market_date)\n",
    "for index in range(len(data_market.time)):\n",
    "    market_date[index] = data_market.time[index].date()\n",
    "data_market.time = market_date\n",
    "del market_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='ZNGA.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='SHLD.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='MAT.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='BBBY.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='DISH.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='NDAQ.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='PCAR.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2016-07-06','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='PIZZA.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[data_market['open'] > 2000].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[((data_market.assetCode == 'TW.N') &\\\n",
    "                        (data_market.time >= datetime.strptime('2009-12-16','%Y-%m-%d').date())&\\\n",
    "                        (data_market.time < datetime.strptime('2010-01-08','%Y-%m-%d').date()))].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[data_market.returnsOpenPrevRaw1 > 10].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2011-12-23','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='PGN.N')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2012-02-15','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='PGN.N')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)\n",
    "\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2012-01-09','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='PGN.N')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[(data_market['time'] >= datetime.strptime('2016-10-01','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='EBR.N')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean market data\n",
    "drop_row = data_market[(data_market['time'] == datetime.strptime('2009-08-03','%Y-%m-%d').date())&\\\n",
    "                       (data_market['assetCode']=='HGSI.O')].index.values\n",
    "data_market = data_market.drop(drop_row, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'time', 'assetCode', 'assetName', 'volume', 'close',\n",
       "       'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n",
       "       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n",
       "       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n",
       "       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n",
       "       'returnsOpenNextMktres10', 'universe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_market.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnamed column\n",
    "data_market = data_market.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save new market data \n",
    "market_new = '../DataSet/market_clean.csv'\n",
    "data_market.to_csv(market_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned market data to new file\n",
    "data_market = pd.read_csv('../DataSet/market_clean.csv', parse_dates =[1])\n",
    "data_market = data_market.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN rows from data set\n",
    "data_market = data_market.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Replace date time object with just the date \n",
    "market_date = np.empty(len(data_market.time))\n",
    "market_date = pd.Series(market_date)\n",
    "for index in range(len(data_market.time)):\n",
    "    market_date[index] = data_market.time.iloc[index].date()\n",
    "data_market.time = market_date\n",
    "del market_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load news data\n",
    "file_news = '../DataSet/news_train_df.csv'\n",
    "data_news = pd.read_csv(file_news, parse_dates = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'time', 'sourceTimestamp', 'firstCreated', 'sourceId',\n",
       "       'headline', 'urgency', 'takeSequence', 'provider', 'subjects',\n",
       "       'audiences', 'bodySize', 'companyCount', 'headlineTag',\n",
       "       'marketCommentary', 'sentenceCount', 'wordCount', 'assetCodes',\n",
       "       'assetName', 'firstMentionSentence', 'relevance', 'sentimentClass',\n",
       "       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n",
       "       'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n",
       "       'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n",
       "       'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n",
       "       'volumeCounts7D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_news.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnamed column\n",
    "data_news = data_news.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#Create new column of datetime with just date for news data\n",
    "news_date = np.empty(len(data_news.time))\n",
    "news_date = pd.Series(news_date)\n",
    "for index in range(len(data_news.time)):\n",
    "    news_date[index] = data_news.time[index].date()\n",
    "data_news.time = news_date\n",
    "del news_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naively merge data along time and company name \n",
    "data_merged = pd.merge(data_market, data_news, on = ['time', 'assetName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'time', 'assetCode', 'assetName', 'volume', 'close',\n",
       "       'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n",
       "       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n",
       "       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n",
       "       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n",
       "       'returnsOpenNextMktres10', 'universe', 'sourceTimestamp',\n",
       "       'firstCreated', 'sourceId', 'headline', 'urgency', 'takeSequence',\n",
       "       'provider', 'subjects', 'audiences', 'bodySize', 'companyCount',\n",
       "       'headlineTag', 'marketCommentary', 'sentenceCount', 'wordCount',\n",
       "       'assetCodes', 'firstMentionSentence', 'relevance', 'sentimentClass',\n",
       "       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n",
       "       'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n",
       "       'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n",
       "       'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n",
       "       'volumeCounts7D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save merged data to file\n",
    "merged_file = '../DataSet/merged_data2.csv'\n",
    "data_merged.to_csv(merged_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
